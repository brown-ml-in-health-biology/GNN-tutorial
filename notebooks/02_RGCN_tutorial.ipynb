{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e44066c",
      "metadata": {},
      "source": [
        "# Merged Tutorial: R-GCN Link Prediction\n",
        "\n",
        "In this notebook, we’ll demonstrate how to use a **Relational Graph Convolutional Network (R-GCN)** for **link prediction**.\n",
        "We will cover:\n",
        "1. Loading and Preparing the Dataset\n",
        "2. Building an R-GCN Model\n",
        "3. **Training and Optimization**\n",
        "4. **Evaluation Metrics and Scoring (Precision, Recall, Cohen’s Kappa)**\n",
        "5. **Visualization and Interpretability**\n",
        "6. **Interactive Elements** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a420110f",
      "metadata": {},
      "source": [
        "## 1. Installation and Imports\n",
        "\n",
        "Below we install and import the required libraries if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db16b85",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you need to install PyTorch Geometric:\n",
        "# !pip install torch torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd9bef3",
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import RGCNConv\n",
        "\n",
        "# for evaluation:\n",
        "from sklearn.metrics import precision_score, recall_score, cohen_kappa_score\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"PyTorch Geometric imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94739ef0",
      "metadata": {},
      "source": [
        "## 2. Load and Prepare the Dataset\n",
        "\n",
        "Here, we create or load a small synthetic relational graph. In practice, replace this with your real dataset. We also split edges into training, validation, and test sets for link prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2bbc4ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthetic example with two relations (0 and 1)\n",
        "edge_index = torch.tensor([\n",
        "    [0, 1, 1, 2, 2, 3, 4, 5],  # Source nodes\n",
        "    [1, 0, 2, 1, 3, 2, 1, 3]   # Target nodes\n",
        "], dtype=torch.long)\n",
        "\n",
        "# Relation types (one per edge)\n",
        "edge_type = torch.tensor([0, 0, 1, 1, 0, 1, 0, 1], dtype=torch.long)\n",
        "\n",
        "# Node features (dummy identity matrix for demonstration)\n",
        "x = torch.eye(4, 4)\n",
        "\n",
        "data = Data(\n",
        "    x=x,\n",
        "    edge_index=edge_index\n",
        ")\n",
        "data.edge_type = edge_type\n",
        "\n",
        "print(data)\n",
        "\n",
        "# Split edges into train/val/test\n",
        "num_edges = data.edge_index.size(1)\n",
        "train_size = int(num_edges * 0.6)\n",
        "val_size = int(num_edges * 0.2)\n",
        "\n",
        "indices = torch.randperm(num_edges)\n",
        "train_idx = indices[:train_size]\n",
        "val_idx = indices[train_size:train_size + val_size]\n",
        "test_idx = indices[train_size + val_size:]\n",
        "\n",
        "train_edge_index = data.edge_index[:, train_idx]\n",
        "train_edge_type = data.edge_type[train_idx]\n",
        "val_edge_index = data.edge_index[:, val_idx]\n",
        "val_edge_type = data.edge_type[val_idx]\n",
        "test_edge_index = data.edge_index[:, test_idx]\n",
        "test_edge_type = data.edge_type[test_idx]\n",
        "\n",
        "train_edge_index, train_edge_type, val_edge_index, val_edge_type, test_edge_index, test_edge_type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6253ce7a",
      "metadata": {},
      "source": [
        "## 3. Building the R-GCN Model\n",
        "\n",
        "Below is a minimal R-GCN for link prediction:\n",
        "- It uses learned node embeddings or provided features.\n",
        "- Multiple RGCNConv layers.\n",
        "- A simple concatenation-based scoring function for edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b060260e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RGCNLinkPredictor(nn.Module):\n",
        "    def __init__(self, num_nodes, in_channels, out_channels, num_relations, num_layers=2):\n",
        "        super().__init__()\n",
        "        # Node embeddings (if nodes lack inherent features)\n",
        "        self.node_embeddings = nn.Embedding(num_nodes, in_channels)\n",
        "\n",
        "        # RGCN layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(\n",
        "            RGCNConv(in_channels, out_channels, num_relations=num_relations)\n",
        "        )\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(\n",
        "                RGCNConv(out_channels, out_channels, num_relations=num_relations)\n",
        "            )\n",
        "\n",
        "        # Linear scoring layer\n",
        "        self.scoring = nn.Linear(out_channels * 2, 1)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.node_embeddings.weight)\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        nn.init.xavier_uniform_(self.scoring.weight)\n",
        "        if self.scoring.bias is not None:\n",
        "            nn.init.zeros_(self.scoring.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_type):\n",
        "        # If x is None, we use the learned embeddings entirely.\n",
        "        if x is None:\n",
        "            out = self.node_embeddings.weight\n",
        "        else:\n",
        "            # Example: Summation of learned embeddings and provided features\n",
        "            emb = self.node_embeddings.weight\n",
        "            out = emb + x\n",
        "\n",
        "        # Pass through R-GCN layers\n",
        "        for conv in self.convs:\n",
        "            out = conv(out, edge_index, edge_type)\n",
        "            out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def predict(self, node_embeddings, edge_index):\n",
        "        # node_embeddings: [num_nodes, out_channels]\n",
        "        source = node_embeddings[edge_index[0]]\n",
        "        target = node_embeddings[edge_index[1]]\n",
        "        # Concat node embeddings and feed to scoring\n",
        "        score = self.scoring(torch.cat([source, target], dim=-1))\n",
        "        return torch.sigmoid(score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0a290d",
      "metadata": {},
      "source": [
        "## 4. Training and Optimization\n",
        "\n",
        "In link prediction, we often optimize by contrasting positive edges (from the graph) with negative edges (sampled randomly or via more advanced strategies). Here, we:\n",
        "\n",
        "1. Generate negative samples.\n",
        "2. Compute link likelihood for both positive and negative edges.\n",
        "3. Use a binary cross-entropy style loss (via manual log-likelihoods) to distinguish between them.\n",
        "4. Use an optimizer (e.g., Adam) to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac2f2635",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_nodes = data.num_nodes\n",
        "num_relations = int(torch.max(data.edge_type)) + 1\n",
        "in_channels = 8  # hidden dimension for the embedding\n",
        "out_channels = 8\n",
        "\n",
        "model = RGCNLinkPredictor(\n",
        "    num_nodes=num_nodes,\n",
        "    in_channels=in_channels,\n",
        "    out_channels=out_channels,\n",
        "    num_relations=num_relations,\n",
        "    num_layers=2\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "data = data.to(device)\n",
        "\n",
        "# Move splits to device\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_edge_type = train_edge_type.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_edge_type = val_edge_type.to(device)\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_edge_type = test_edge_type.to(device)\n",
        "\n",
        "def negative_sampling(num_neg_samples, num_nodes):\n",
        "    # Random negative edges\n",
        "    i = torch.randint(0, num_nodes, (num_neg_samples,), device=device)\n",
        "    j = torch.randint(0, num_nodes, (num_neg_samples,), device=device)\n",
        "    return torch.stack([i, j], dim=0)\n",
        "\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    node_embeddings = model(data.x, train_edge_index, train_edge_type)\n",
        "\n",
        "    # Positive scores\n",
        "    pos_score = model.predict(node_embeddings, train_edge_index)\n",
        "\n",
        "    # Negative scores\n",
        "    neg_edge_index = negative_sampling(train_edge_index.size(1), data.num_nodes)\n",
        "    neg_score = model.predict(node_embeddings, neg_edge_index)\n",
        "\n",
        "    # Compute loss\n",
        "    loss_pos = -torch.log(pos_score + 1e-15).mean()\n",
        "    loss_neg = -torch.log(1 - neg_score + 1e-15).mean()\n",
        "    loss = loss_pos + loss_neg\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Train for a few epochs\n",
        "for epoch in range(1, 21):\n",
        "    loss = train_one_epoch()\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "131d850b",
      "metadata": {},
      "source": [
        "## 5. Evaluation Metrics and Scoring\n",
        "\n",
        "**Precision**, **Recall**, and **Cohen’s Kappa** can provide valuable insights:\n",
        "- **Precision**: Useful when false positives are costly (i.e., predicting edges that do not actually exist).\n",
        "- **Recall**: Critical for ensuring that as many *true* links are recovered as possible.\n",
        "- **Cohen’s Kappa**: Offers insight beyond raw accuracy by considering chance agreement, which helps with imbalanced datasets.\n",
        "\n",
        "Below is an example of how to compute these metrics. We do negative sampling again for the test or validation edges, get scores, and then threshold them to produce predictions. In practice, you might tune this threshold or rely on other decision rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405c1b5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(edge_index, edge_type, threshold=0.5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Obtain node embeddings from the entire graph perspective\n",
        "        node_embeddings = model(data.x, edge_index, edge_type)\n",
        "\n",
        "        # Positive scores\n",
        "        pos_score = model.predict(node_embeddings, edge_index)\n",
        "\n",
        "        # Negative scores (equal number to positive edges)\n",
        "        neg_edge_index = negative_sampling(edge_index.size(1), data.num_nodes)\n",
        "        neg_score = model.predict(node_embeddings, neg_edge_index)\n",
        "\n",
        "    # Construct label vectors\n",
        "    y_true = torch.cat([\n",
        "        torch.ones(pos_score.size(0), device=device),\n",
        "        torch.zeros(neg_score.size(0), device=device)\n",
        "    ], dim=0)\n",
        "\n",
        "    y_scores = torch.cat([pos_score, neg_score], dim=0)\n",
        "    y_pred = (y_scores >= threshold).float()\n",
        "\n",
        "    # Convert tensors to numpy for sklearn compatibility\n",
        "    y_true_np = y_true.cpu().numpy()\n",
        "    y_pred_np = y_pred.cpu().numpy()\n",
        "\n",
        "    precision = precision_score(y_true_np, y_pred_np)\n",
        "    recall = recall_score(y_true_np, y_pred_np)\n",
        "    kappa = cohen_kappa_score(y_true_np, y_pred_np)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'kappa': kappa\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6607ff9",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_val = evaluate(val_edge_index, val_edge_type, threshold=0.5)\n",
        "print(\"Validation Metrics:\", metrics_val)\n",
        "\n",
        "metrics_test = evaluate(test_edge_index, test_edge_type, threshold=0.5)\n",
        "print(\"Test Metrics:\", metrics_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "887a25ad",
      "metadata": {},
      "source": [
        "## 6. Visualization and Interpretability\n",
        "\n",
        "Visualizing or interpreting an R-GCN can be done in various ways:\n",
        "- **Node Embedding Visualization**: Project the learned embeddings (e.g., via PCA or t-SNE) into 2D.\n",
        "- **Edge Score Heatmaps**: If the graph is small, you can illustrate predicted link probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06cee6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad1bf96",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Get final embeddings using the entire graph\n",
        "    embeddings = model(data.x, data.edge_index, data.edge_type).cpu()\n",
        "\n",
        "# Reduce to 2D with PCA\n",
        "pca = PCA(n_components=2)\n",
        "embed_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(embed_2d[:, 0], embed_2d[:, 1])\n",
        "for i in range(embed_2d.shape[0]):\n",
        "    plt.annotate(str(i), (embed_2d[i, 0], embed_2d[i, 1]))\n",
        "plt.title(\"2D PCA Projection of Node Embeddings\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a97d90",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index, data.edge_type)\n",
        "    scores = model.predict(embeddings, data.edge_index).cpu().numpy()\n",
        "\n",
        "# Convert edge_index to numpy for indexing\n",
        "edge_index_np = data.edge_index.cpu().numpy()\n",
        "num_nodes = data.num_nodes\n",
        "\n",
        "# Create empty adjacency matrix\n",
        "adj_matrix = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "# Fill with scores\n",
        "for idx in range(edge_index_np.shape[1]):\n",
        "    src = edge_index_np[0, idx]\n",
        "    dst = edge_index_np[1, idx]\n",
        "    adj_matrix[src, dst] = scores[idx]\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(adj_matrix, cmap='viridis', square=True, cbar_kws={'label': 'Edge Score'})\n",
        "plt.title(\"Predicted Edge Score Heatmap\")\n",
        "plt.xlabel(\"Target Node\")\n",
        "plt.ylabel(\"Source Node\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fba703d",
      "metadata": {},
      "source": [
        "## 10. Interactive Elements\n",
        "\n",
        "For more advanced experimentation, you can use this widget to:\n",
        "- Tune hyperparameters (e.g., learning rate, hidden size) via sliders.\n",
        "- Dynamically update plots of training metrics in real time.\n",
        "\n",
        "Below is a small example showing how you could integrate a widget for toggling the threshold during evaluation. *Make sure you have `ipywidgets` installed (e.g., `pip install ipywidgets`).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33cb5be2",
      "metadata": {
        "tags": [
          "interactive",
          "demo"
        ]
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact, FloatSlider\n",
        "\n",
        "@interact(threshold=FloatSlider(min=0.0, max=1.0, step=0.05, value=0.5))\n",
        "def interactive_evaluation(threshold):\n",
        "    \"\"\"Allows interactive threshold selection for link prediction.\"\"\"\n",
        "    metrics = evaluate(test_edge_index, test_edge_type, threshold=threshold)\n",
        "    print(f\"Threshold: {threshold:.2f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
        "    print(f\"Kappa:     {metrics['kappa']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab569090",
      "metadata": {},
      "source": [
        "Experiment to see how **precision**, **recall**, and **kappa** vary as the decision threshold for link existence changes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5796dc1",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This merged notebook demonstrated:\n",
        "- Loading/preparing a relational graph.\n",
        "- Building an R-GCN for link prediction in PyTorch Geometric.\n",
        "- Training and optimization with negative sampling.\n",
        "- Evaluating using multiple metrics (Precision, Recall, Cohen’s Kappa).\n",
        "- Simple visualization of node embeddings.\n",
        "- Interactive threshold tuning with ipywidgets.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "name": "Merged_RGCN_Tutorial"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
